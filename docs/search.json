[
  {
    "objectID": "note_to_self.html",
    "href": "note_to_self.html",
    "title": "The Gradient Dissident",
    "section": "",
    "text": "command line to resize images : &gt; convert &lt;image_path/image_name.png -resize 1000x1000 new_image_name.png\nexample:\n- convert agents.webp -resize 500x500 thumbnail.webp\n- convert agents.webp -resize 1000x1000 main.webp\n\nClicker sur un lien de fichier present dans le meme dossier post/ (ici un exemple avec requirements.txt de posts/local_agents/) - requirements.txt\nFaire un hover text (et ajouter de la couleur) #| echo: false #| output: asis with open(‚Äòrequirements.txt‚Äô) as f: requirements = f.read().strip()\nprint(f‚ÄôYou can see which dependencies are used for running this notebook by simply hovering over the following : requirements.txt‚Äô)\n\n\n\nAjouter de la couleur dans un mots: requirement.txt\n\n\n\n\nAjouter une image cliquable avec hover text (en couleur) \n\n\n\nAjouter une image en resize dans un post: \n\nAjouter une video:   Your browser does not support the video tag."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome to the Dissension",
    "section": "",
    "text": "üëã Hey there! I‚Äôm Jonathan. Passionate about artificial intelligence and data science, I love exploring the intersection between academic research and real-world applications. My journey has led me to work in AI R&D in North America‚Äôs largest financial cooperative, tackling exciting topics like recommendation systems, reinforcement learning, graph neural networks, and self-supervised learning. But beyond algorithms, what truly drives me is sharing knowledge.\nThat‚Äôs why I started The Gradient Dissident‚Äîa blog where I go from exploring entry-level ideas to breaking down complex AI concepts, all while sharing my thoughts on the field, and maybe, just maybe, challenging conventional wisdom along the way. Why the name? Well, machine learning aficionados are quite familiar with a certain algorithm that methodically fine-tunes models step by step‚Ä¶ But me? I like to question, challenge, and sometimes outright disagree with the status quo‚Äîhence The Gradient Dissident. A little irreverence never hurt anyone, right? üòÑ\nI‚Äôve had the opportunity to teach programming at the HEC Montreal and develop advanced AI training programs. My goal? To make complex concepts accessible and help students, as well as professionals navigate this ever-evolving field. I thrive on bridging the gap between theory and practice, supporting learners of all levels in mastering machine learning.\nSo, whether you‚Äôre here out of curiosity, passion, or professional interest, welcome to The Gradient Dissident! Expect deep dives, fresh insights, and the occasional rebellious take on AI. üöÄ\nStart Reading"
  },
  {
    "objectID": "posts/local_agents/local_agent.html",
    "href": "posts/local_agents/local_agent.html",
    "title": "Building Agents with Tools Locally",
    "section": "",
    "text": "V-LLM Generated Image"
  },
  {
    "objectID": "posts/local_agents/local_agent.html#building-open-source-agents-using-huggingfaces-smolagents",
    "href": "posts/local_agents/local_agent.html#building-open-source-agents-using-huggingfaces-smolagents",
    "title": "Building Agents with Tools Locally",
    "section": "Building Open Source Agents using HuggingFace‚Äôs SmolAgents",
    "text": "Building Open Source Agents using HuggingFace‚Äôs SmolAgents\nTo monitor GPU utilization in real-time, especially when running resource-intensive machine learning tasks, you can leverage the nvidia-smi command. On Ubuntu, simply execute the following command in your terminal (provided that you have an Nvidia GPU):\nwatch -n 1 nvidia-smi\nThis command offers a live, updating snapshot of your GPU‚Äôs performance, enabling you to monitor key metrics such as memory utilization and temperature. The watch -n 1 component ensures that this information is refreshed every second. This is particularly useful for debugging, optimizing your machine learning workflows, and identifying specific commands or models that lead to critical ‚ÄúOut Of Memory‚Äù errors.\n\nImports & Setup\nIn this initial code block, we start by importing the necessary libraries to construct our local AI agent. Let‚Äôs break down the important imports:\n\ntyping: A module to provide type hints for our function signatures, which is a critical part of creating useful tools that our agents that use.\nsmolagents: From the smolagents library, we import:\n\nTool: A base class for defining custom tools that our agent can use.\nCodeAgent: The core class for creating agents capable of generating and executing code.\nTransformersModel: A class to load and manage transformer models.\ntool: A decorator to easily register functions as tools for the agent.\nDuckDuckGoSearchTool: A pre-built tool that allows the agent to perform web searches using DuckDuckGo.\n\nyaml: This library is imported to handle YAML configuration files, allowing us to define agent settings in a structured format.\nyfinance: We import yfinance to fetch stock market data.\n\nThese imports set the stage for building a powerful AI agent that can interact with its environment through code execution and web searches.\nYou can see which dependencies are used for running this notebook by either simply hovering over requirements.txt or by opening it in another window.\n\nfrom datetime import datetime\nfrom typing import Any\n\nimport pytz\nfrom smolagents import CodeAgent, TransformersModel, tool, DuckDuckGoSearchTool\nfrom smolagents.tools import Tool\nimport yaml\nimport yfinance as yf\n\n\n\nDefine your prompt template\nLoad up the adequate yaml prompt template. This one is compatible with the smolagents library and the model we will use. It was taken directly from HuggingFace‚Äôs Agents Course.\n\n# Setting up the predefined prompts\nwith open(\"prompts.yaml\", 'r') as stream:\n    prompt_templates = yaml.safe_load(stream)\n\n\n\nUnderstanding AI Tool Creation with SmolAgents\nWhen building AI agents, defining tools properly is crucial for ensuring smooth integration with frameworks like SmolAgents.\nThe first tool we will build today uses the yfinance library to check the status (price) of a given ticker on the North American stock market.\n\nCreating your first tool\nThe function check_NA_market_status is decorated with @tool, marking it as a callable tool within the agent framework. This tool checks whether the stock market is open and returns the latest stock price if open, or the last closing price if closed.\n\nAppropriate type-hinting is Essential\n\nThe function takes a single string argument (ticker: str) and returns a string (-&gt; str).\n\nThis typing ensures that the agent understands the expected input and output format.\n\nWithout this, the function may not work correctly in an AI pipeline.\n\nThe Importance of a Docstring\n\nThe function is documented with a clear, structured docstring explaining:\n\nWhat it does (checks if the market is open and returns the appropriate stock price).\n\nWhat arguments it takes (ticker ‚Äì the stock ticker symbol).\n\nWhat it returns (a formatted string with market status and price).\n\n\nAI agents rely on this information to understand the function‚Äôs role. When/if you build your own tool, it is critical to keep the same docstring template for your code to be compatible with the smolagents library.\n\n\n\nKey Takeaways for developping tools\n\nFollow the function template: Use clear type hints and structured docstrings.\n\nEnsure proper decoration: The @tool decorator registers the function within the SmolAgents framework.\n\nKeep return types simple: AI models parse these results, so returning formatted strings helps with interpretability.\n\nThis structured approach makes it easier for Agents to call tools correctly, understand their functions, and use them effectively in reasoning and decision-making.\n\n@tool\ndef check_NA_market_status(ticker: str) -&gt; str:\n    \"\"\"\n    A tool that checks if the stock market is open for the given ticker and returns the \n    current price if open,or the previous close price if the market is closed.\n    Args:\n        ticker: The stock ticker symbol (e.g., 'AAPL', 'GOOG').\n    Returns:\n        A message indicating whether the market is open or closed, \n        and the price of the stock at the respective time.\n    \"\"\"\n\n    # Get the current time in Eastern Time Zone\n    eastern = pytz.timezone('US/Eastern')\n    now = datetime.now(eastern)\n    parsed_now = now.strftime(\"%A %B %d at %H:%M EST\")\n    current_time = now.time()\n    current_day = now.weekday()  # Monday is 0 and Sunday is 6\n\n    market_open_time = datetime.strptime(\"09:30:00\", \"%H:%M:%S\").time()\n    market_close_time = datetime.strptime(\"16:00:00\", \"%H:%M:%S\").time()\n\n    if current_day &lt; 5 and market_open_time &lt;= current_time &lt;= market_close_time:\n        stock = yf.Ticker(ticker)\n        # Request intraday data: 1-day period with 1-minute interval\n        current_price = stock.history(period=\"1d\", interval=\"1m\")['Close'].iloc[-1]\n        return f\"\"\"As of {parsed_now}, the market is open.\\n    \n        The current price of {ticker} is: ${current_price:.2f}\"\"\"\n    else:\n        stock = yf.Ticker(ticker)\n        previous_close = stock.history(period=\"1d\")['Close'].iloc[-1]\n        return f\"\"\"As of {parsed_now}, the market is closed.\\n\n        The previous close price of {ticker} was ${previous_close:.2f}\"\"\"\n\n\n\n\n\nBypassing LLM‚Äôs mathematical computation limitations\nThe fibonacci_tool function is a custom tool designed to compute the nth Fibonacci number. It is decorated with @tool, which allows it to be seamlessly integrated into an AI agent using the SmolAgents framework.\nLLMs, while powerful, often struggle with mathematical computations, especially recursive sequences like Fibonacci numbers. Instead of relying on the LLM‚Äôs built-in reasoning which fails, for example, to return Fibonacci numbers past a certain number of steps even with the most powerful models like GPT-4o and o1 - try it for yourself; this tool:\n\nProvides a deterministic and accurate calculation of Fibonacci numbers.\nIs significantly more efficient than recursive implementations, using an iterative approach to avoid excessive function calls.\nEnsures the AI agent always returns correct numerical results rather than relying on approximate or hallucinated values. \n\n\n# second tool\n@tool\ndef fibonacci_tool(n: int) -&gt; int:\n    \"\"\"\n    A simple tool that returns the nth Fibonacci number.\n\n    Args:\n        n: The index of the Fibonacci sequence to retrieve (int)\n\n    Returns:\n        int: The nth Fibonacci number.\n    \"\"\"\n    if n &lt;= 0:\n        return 0\n    elif n == 1:\n        return 1\n    else:\n        a, b = 0, 1\n        for _ in range(2, n + 1):\n            a, b = b, a + b\n        return b\n\n\n\nBypassing the LLM‚Äôs training date cutoff\nFinally, we leverage smolagent‚Äôs DuckDuckGoSearchTool to create a tool able to fetch up-to-date information from the web.\nThis tool empowers our agent with the ability to quickly retrieve relevant information on demand. Since models training have cutoff dates, this tool will allow us to bypass this cutoff limitation by researching the web for up to date answers to any query we may have.\n\n# third tool\n@tool\ndef duckduckgo_search(query: str) -&gt; str:\n    \"\"\"\n    A tool that performs a real-time DuckDuckGo search for the given query \n    and returns the top results.\n    \n    Args:\n        query: The search query string (e.g., \"Latest AI research 2025\").\n        \n    Returns:\n        A string containing the search results. If the search tool returns \n        a formatted string, it is returned directly; otherwise, if it \n        returns a list of dictionaries with 'title' and 'url' keys,\n        the results are formatted for readability.\n    \"\"\"\n    search_tool = DuckDuckGoSearchTool()\n    results = search_tool(query)\n    \n    if isinstance(results, str):\n        return results\n    \n    formatted_results = \"\\n\".join(\n        [f\"{item.get('title', 'No Title')} -&gt; {item.get('url', 'No URL')}\" \n         for item in results]\n    )\n    return formatted_results\n\n\n\nUnderstanding the Final Answer Tool in AI Agents\nThe FinalAnswerTool is a specialized tool used in AI agent frameworks to consolidate the reasoning process and provide a definitive response. Unlike other tools that fetch data or perform computations, this tool acts as a final step where the AI commits to a structured output.\n\nWhy This Tool Is Important for AI Agents\nAI agents often go through multi-step reasoning before arriving at an answer. The FinalAnswerTool helps in:\n\nEnsuring a structured final response\n\nInstead of returning intermediate steps, the agent commits to a well-defined answer.\n\nImproving interpretability\n\nBy using a dedicated final output tool, responses become more consistent and easier to process.\n\nIntegrating seamlessly into pipelines\n\nMany agent frameworks expect a clear final output format‚Äîthis tool standardizes the output handling.\n\n\nWhen designing AI agents, tools like this help bridge the gap between reasoning and action, making interactions smoother and more reliable.\nNote: The FinalAnswerTool part of the CodeAgent is currently bugged, as MultiStepAgent from the smolagents library silently overwrites parameter-provided FinalAnswerTool, but I assume the HF team will fix it soon. The version presented below is the static version. If you try to overwrite it, it won‚Äôt change anything (for now)\n\n# final answer class tool used after reasoning\nclass FinalAnswerTool(Tool):\n    name = \"final_answer\"\n    description = \"Provides a final answer to the given problem.\"\n    inputs = {'answer': {'type': 'any', 'description': 'The final answer to the problem'}}\n    output_type = \"any\"\n\n    def forward(self, answer: Any) -&gt; Any:\n        return answer\n\n    def __init__(self, *args, **kwargs):\n        self.is_initialized = False\n\n# instanciate tool\nfinal_answer = FinalAnswerTool()\n\n\n\n\nPicking our LLM and initializing it.\nTo instanciate our agent, we must first create a model instance by setting up a specific TransformersModel and its tokenizer (with CUDA enabled and controlled token limits).\nHere is a link to the model card of the HuggingFace LLM we will be using today ü§ó\n\n# pick a model and instanciate it; smaller models risk giving erroneous answers\n# but you can use those if you don't have enough memory\n\n# model_name = \"HuggingFaceTB/SmolLM-135M-Instruct\"\n# model_name= \"HuggingFaceTB/SmolLM2-360M-Instruct\"\nmodel_name=\"HuggingFaceTB/SmolLM2-1.7B-Instruct\"\n\nmodel = TransformersModel(model_id=model_name, device_map=\"auto\", max_new_tokens=200)\n\n\n\nCreating an AI Agent with Custom Tools\nNow that we‚Äôve built our individual tools, the next step is assembling them into an AI agent. This is done using the CodeAgent class, which takes a language model (model), a set of tools, and other parameters to define its behavior.\nKey Components of the AI Agent:\n\nModel (model) ‚Äì The LLM that powers the agent‚Äôs reasoning and decision-making.\nTools (tools) ‚Äì A list of functions the agent can use to extend its capabilities.\nMax Steps (max_steps=6) ‚Äì Limits how many steps the agent can take before finalizing an answer.\nVerbosity (verbosity_level=1) ‚Äì Controls the level of detail in logs/debugging output.\nPrompt Templates (prompt_templates) ‚Äì Provides structured instructions for the agent‚Äôs behavior.\n\n\n# finaly, create the agent and pass the model, tools, \n# number of steps it should reflect for, prompt template...ect\n\nagent = CodeAgent(\n    model=model,\n    tools=[final_answer,fibonacci_tool, check_NA_market_status, duckduckgo_search], \n    max_steps=6,\n    verbosity_level=1,\n    grammar=None,\n    planning_interval=None,\n    name=None,\n    description=None,\n    prompt_templates=prompt_templates\n)\n\nFinally, we query our agent by passing in our queries to the .run() method.\n\nprint(\"CodeAgent:\", agent.run(\"Could you give me the 118th number in the Fibonacci sequence?\"))\n\n‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ New run ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ\n‚îÇ                                                                                                                 ‚îÇ\n‚îÇ Could you give me the 118th number in the Fibonacci sequence?                                                   ‚îÇ\n‚îÇ                                                                                                                 ‚îÇ\n‚ï∞‚îÄ TransformersModel - HuggingFaceTB/SmolLM2-1.7B-Instruct ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ\n\n\n\n‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ Step 1 ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n\n\n\n ‚îÄ Executing parsed code: ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ \n  answer = fibonacci_tool(n=118)                                                                                   \n  final_answer(answer)                                                                                             \n ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ \n\n\n\nOut - Final answer: 2046711111473984623691759\n\n\n\n[Step 0: Duration 4.87 seconds| Input tokens: 2,514 | Output tokens: 63]\n\n\n\nCodeAgent: 2046711111473984623691759\n\n\n\nprint(\"CodeAgent:\", agent.run(\"Could you give me the current market price of the stock NVDA Corp.?\"))\n\n‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ New run ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ\n‚îÇ                                                                                                                 ‚îÇ\n‚îÇ Could you give me the current market price of the stock NVDA Corp.?                                             ‚îÇ\n‚îÇ                                                                                                                 ‚îÇ\n‚ï∞‚îÄ TransformersModel - HuggingFaceTB/SmolLM2-1.7B-Instruct ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ\n\n\n\n‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ Step 1 ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n\n\n\n ‚îÄ Executing parsed code: ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ \n  ticker = 'NVDA'                                                                                                  \n  current_price = check_NA_market_status(ticker)                                                                   \n  final_answer(current_price)                                                                                      \n ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ \n\n\n\nOut - Final answer: As of Saturday February 22 at 22:25 EST, the market is closed.\n\n        The previous close price of NVDA was $134.43\n\n\n\n[Step 0: Duration 5.46 seconds| Input tokens: 2,512 | Output tokens: 78]\n\n\n\nCodeAgent: As of Saturday February 22 at 22:25 EST, the market is closed.\n\n        The previous close price of NVDA was $134.43\n\n\n\nprint(\"CodeAgent:\", agent.run(\"Could you search the web for the latest AI research in 2025\"))\n\n‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ New run ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ\n‚îÇ                                                                                                                 ‚îÇ\n‚îÇ Could you search the web for the latest AI research in 2025                                                     ‚îÇ\n‚îÇ                                                                                                                 ‚îÇ\n‚ï∞‚îÄ TransformersModel - HuggingFaceTB/SmolLM2-1.7B-Instruct ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ\n\n\n\n‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ Step 1 ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n\n\n\n ‚îÄ Executing parsed code: ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ \n  query = \"Latest AI research 2025\"                                                                                \n  result = duckduckgo_search(query=query)                                                                          \n  final_answer(result)                                                                                             \n ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ \n\n\n\nOut - Final answer: ## Search Results\n\n[The 10 Biggest AI Trends Of 2025 Everyone Must Be Ready For Today - \nForbes](https://www.forbes.com/sites/bernardmarr/2024/09/24/the-10-biggest-ai-trends-of-2025-everyone-must-be-ready\n-for-today/)\nDiscover the 10 major AI trends set to reshape 2025: from augmented working and real-time decision-making to \nadvanced AI legislation and sustainable AI initiatives.\n\n[AI in the workplace: A report for 2025 | McKinsey - McKinsey & \nCompany](https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/superagency-in-the-workplace-empowerin\ng-people-to-unlock-ais-full-potential-at-work)\nArtificial intelligence has arrived in the workplace and has the potential to be as transformative as the steam \nengine was to the 19th-century Industrial Revolution. 1 \"Gen AI: A cognitive industrial revolution,\" McKinsey, June\n7, 2024. With powerful and capable large language models (LLMs) developed by Anthropic, Cohere, Google, Meta, \nMistral, OpenAI, and others, we have entered a new ...\n\n[Five Trends in AI and Data Science for 2025 - MIT Sloan Management \nReview](https://sloanreview.mit.edu/article/five-trends-in-ai-and-data-science-for-2025/)\nBut we will incorporate the latest research whenever possible. Randy has just completed his annual survey of data, \nanalytics, and AI executives, the 2025 AI & Data Leadership Executive Benchmark Survey, conducted by his \neducational firm, Data & AI Leadership Exchange; and Tom has worked on several surveys on generative AI and data, \ntechnology ...\n\n[What's next for AI in 2025 - MIT Technology \nReview](https://www.technologyreview.com/2025/01/08/1109188/whats-next-for-ai-in-2025/)\nAI model makers are also keen to pitch their generative products as research tools for scientists. OpenAI let \nscientists test its latest o1 model and see how it might support them in research. The ...\n\n[Artificial Intelligence | Stanford Emerging Technology \nReview](https://setr.stanford.edu/technology/artificial-intelligence/2025)\n‚Ä¢ Artificial intelligence (AI) is a foundational technology that is supercharging other scientific fields and, like\nelectricity and the internet, has the potential to transform societies, economies, and politics worldwide. ... \nResearch on foundational AI technologies is difficult to regulate, even among likeminded nations. It is even more \n...\n\n[Top 15 AI Trends for 2025: Expert Predictions You Need to \nKnow](https://techstartups.com/2025/01/01/top-15-ai-trends-for-2025-expert-predictions-you-need-to-know/)\n3. Open-Source AI Gains Momentum Last week, we wrote about how Deepseek outperformed OpenAI and Meta's latest \nmodels at a fraction of the cost.Deepseek, a free open-source AI model developed by a Chinese tech startup, \nexemplifies a growing trend in open-source AI, where accessible tools are pushing the boundaries of performance and\naffordability.\n\n[Predictions for AI in 2025: Collaborative Agents, AI Skepticism, and \n...](https://hai.stanford.edu/news/predictions-ai-2025-collaborative-agents-ai-skepticism-and-new-risks)\nIn 2025, we will see a significant shift from relying on individual AI models to using systems where multiple AI \nagents of diverse expertise work together. As an example, we recently introduced the Virtual Lab , where a \nprofessor AI agent leads a team of AI scientist agents (e.g., AI chemist, AI biologist) to tackle challenging, \nopen-ended ...\n\n[AI Advancements in 2025: The Next Big Innovations to \nWatch](https://techresearchs.com/artificial-intelligence/ai-advancements-in-2025-the-next-big-innovations-to-watch/\n)\nArtificial Intelligence (AI) continues to evolve, reshaping industries and daily life. In 2025, AI advancements \nwill bring groundbreaking innovations, enhancing automation, decision-making, and problem-solving across various \nsectors. This article explores the latest AI advancements in 2025, their applications, and their transformative \nimpact on businesses and society.\n\n[10 AI Predictions For 2025 - Forbes](https://www.forbes.com/sites/robtoews/2024/12/22/10-ai-predictions-for-2025/)\n1. Meta will begin charging for use of its Llama models. Meta is the world's standard bearer for open-weight AI. In\na fascinating case study in corporate strategy, while rivals like OpenAI and ...\n\n[AI in 2025: The Most Exciting Developments to \nExpect](https://techresearchs.com/artificial-intelligence/ai-in-2025-the-most-exciting-developments-to-expect/)\nHow will AI affect education by 2025?AI will provide personalized learning experiences, real-time assessments, and \nvirtual learning assistants, making education more efficient and accessible. The developments expected in AI in \n2025 will reshape industries, improve lives, and bring about new opportunities. From AI-powered automation to ...\n\n\n\n[Step 0: Duration 6.65 seconds| Input tokens: 2,513 | Output tokens: 82]\n\n\n\nCodeAgent: ## Search Results\n\n[The 10 Biggest AI Trends Of 2025 Everyone Must Be Ready For Today - Forbes](https://www.forbes.com/sites/bernardmarr/2024/09/24/the-10-biggest-ai-trends-of-2025-everyone-must-be-ready-for-today/)\nDiscover the 10 major AI trends set to reshape 2025: from augmented working and real-time decision-making to advanced AI legislation and sustainable AI initiatives.\n\n[AI in the workplace: A report for 2025 | McKinsey - McKinsey & Company](https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/superagency-in-the-workplace-empowering-people-to-unlock-ais-full-potential-at-work)\nArtificial intelligence has arrived in the workplace and has the potential to be as transformative as the steam engine was to the 19th-century Industrial Revolution. 1 \"Gen AI: A cognitive industrial revolution,\" McKinsey, June 7, 2024. With powerful and capable large language models (LLMs) developed by Anthropic, Cohere, Google, Meta, Mistral, OpenAI, and others, we have entered a new ...\n\n[Five Trends in AI and Data Science for 2025 - MIT Sloan Management Review](https://sloanreview.mit.edu/article/five-trends-in-ai-and-data-science-for-2025/)\nBut we will incorporate the latest research whenever possible. Randy has just completed his annual survey of data, analytics, and AI executives, the 2025 AI & Data Leadership Executive Benchmark Survey, conducted by his educational firm, Data & AI Leadership Exchange; and Tom has worked on several surveys on generative AI and data, technology ...\n\n[What's next for AI in 2025 - MIT Technology Review](https://www.technologyreview.com/2025/01/08/1109188/whats-next-for-ai-in-2025/)\nAI model makers are also keen to pitch their generative products as research tools for scientists. OpenAI let scientists test its latest o1 model and see how it might support them in research. The ...\n\n[Artificial Intelligence | Stanford Emerging Technology Review](https://setr.stanford.edu/technology/artificial-intelligence/2025)\n‚Ä¢ Artificial intelligence (AI) is a foundational technology that is supercharging other scientific fields and, like electricity and the internet, has the potential to transform societies, economies, and politics worldwide. ... Research on foundational AI technologies is difficult to regulate, even among likeminded nations. It is even more ...\n\n[Top 15 AI Trends for 2025: Expert Predictions You Need to Know](https://techstartups.com/2025/01/01/top-15-ai-trends-for-2025-expert-predictions-you-need-to-know/)\n3. Open-Source AI Gains Momentum Last week, we wrote about how Deepseek outperformed OpenAI and Meta's latest models at a fraction of the cost.Deepseek, a free open-source AI model developed by a Chinese tech startup, exemplifies a growing trend in open-source AI, where accessible tools are pushing the boundaries of performance and affordability.\n\n[Predictions for AI in 2025: Collaborative Agents, AI Skepticism, and ...](https://hai.stanford.edu/news/predictions-ai-2025-collaborative-agents-ai-skepticism-and-new-risks)\nIn 2025, we will see a significant shift from relying on individual AI models to using systems where multiple AI agents of diverse expertise work together. As an example, we recently introduced the Virtual Lab , where a professor AI agent leads a team of AI scientist agents (e.g., AI chemist, AI biologist) to tackle challenging, open-ended ...\n\n[AI Advancements in 2025: The Next Big Innovations to Watch](https://techresearchs.com/artificial-intelligence/ai-advancements-in-2025-the-next-big-innovations-to-watch/)\nArtificial Intelligence (AI) continues to evolve, reshaping industries and daily life. In 2025, AI advancements will bring groundbreaking innovations, enhancing automation, decision-making, and problem-solving across various sectors. This article explores the latest AI advancements in 2025, their applications, and their transformative impact on businesses and society.\n\n[10 AI Predictions For 2025 - Forbes](https://www.forbes.com/sites/robtoews/2024/12/22/10-ai-predictions-for-2025/)\n1. Meta will begin charging for use of its Llama models. Meta is the world's standard bearer for open-weight AI. In a fascinating case study in corporate strategy, while rivals like OpenAI and ...\n\n[AI in 2025: The Most Exciting Developments to Expect](https://techresearchs.com/artificial-intelligence/ai-in-2025-the-most-exciting-developments-to-expect/)\nHow will AI affect education by 2025?AI will provide personalized learning experiences, real-time assessments, and virtual learning assistants, making education more efficient and accessible. The developments expected in AI in 2025 will reshape industries, improve lives, and bring about new opportunities. From AI-powered automation to ...\n\n\n\n\nConclusion\nIn this tutorial, we‚Äôve demonstrated that it‚Äôs possible to build powerful AI assistants that run entirely on your local machine while still maintaining access to current information through web searches. The combination of local processing and internet connectivity offers a balanced solution between privacy, cost-effectiveness, and up-to-date information access.\nWhile this implementation uses specific tools and models, the concepts can be adapted to work with different LLMs or search engines based on your needs. The modular nature of the code allows for easy extensions and modifications.\nFeel free to experiment with:\n\nDifferent LLM models\nAdditional custom tools\nAlternative search engines\nEnhanced prompting strategies\n\nThe code for this project is available on GitHub.\nIf you have any questions or want to get in touch, don‚Äôt hesitate!\n\nüíº Connect with me on LinkedIn\n\nüì´ Send me an email\n\nHappy coding! üöÄ"
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "The Blog",
    "section": "",
    "text": "Building Agents with Tools Locally\n\n\n\n\n\n\ntutorial\n\n\ncode\n\n\n\nBuilding an AI Agent with tools locally using HuggingFace SmolAgents and Transformers Libraries\n\n\n\n\n\nFeb 21, 2025\n\n\n\n\n\n\nNo matching items"
  }
]